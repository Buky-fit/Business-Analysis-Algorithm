{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\EBUKA\\Documents\\Business Analysis Algorithm\\social_data\\social_media_engagement.csv')\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "'''# Split the post_time column into date and time columns\n",
    "df[['date', 'time']] = df['post_time'].str.split(' ', expand=True)\n",
    "\n",
    "# Convert the date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Convert the time column to time\n",
    "df['time'] = pd.to_datetime(df['time'], format='%H:%M').dt.time\n",
    "\n",
    "# Drop the original post_time column if no longer needed\n",
    "df.drop(columns=['post_time'], inplace=True)\n",
    "\n",
    "# Reorder the columns to place 'date' and 'time' after 'post_type'\n",
    "cols = df.columns.tolist()\n",
    "post_type_index = cols.index('post_type')\n",
    "new_order = cols[:post_type_index + 1] + ['date','post_day', 'time'] + cols[post_type_index + 1:]\n",
    "\n",
    "new_order = [col for col in new_order if col not in ['date','post_day', 'time']]\n",
    "new_order.insert(post_type_index + 1, 'date')\n",
    "new_order.insert(post_type_index + 2, 'post_day')\n",
    "new_order.insert(post_type_index + 3, 'time')\n",
    "\n",
    "# Reorder the columns in the dataframe\n",
    "df = df[new_order]\n",
    "\n",
    "# Present date as Day-Month-Year\n",
    "df['date'] = df['date'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Present time as 12-hour format with AM/PM\n",
    "df['time'] = df['time'].apply(lambda x: x.strftime('%I:%M %p'))\n",
    "\n",
    "# Display the dataframe info\n",
    "df['post_type'].value_counts()'''\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect outliers using the IQR method\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"\n",
    "    Detect outliers in a DataFrame column using the IQR method.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame\n",
    "        column (str): Column name to analyze\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Subset of rows containing outliers\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the column exists and is numeric\n",
    "        if column not in data.columns:\n",
    "            raise ValueError(f\"Column '{column}' not found in DataFrame\")\n",
    "        if not pd.api.types.is_numeric_dtype(data[column]):\n",
    "            raise ValueError(f\"Column '{column}' must be numeric\")\n",
    "        \n",
    "        Q1 = data[column].quantile(0.25)\n",
    "        Q3 = data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "        return outliers\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing column '{column}': {e}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame on error\n",
    "\n",
    "# Detect outliers for engagement metrics\n",
    "outliers_likes = detect_outliers_iqr(df, \"num_likes\")\n",
    "outliers_comments = detect_outliers_iqr(df, \"num_comments\")\n",
    "outliers_shares = detect_outliers_iqr(df, \"num_shares\")\n",
    "\n",
    "# Count of outliers in each column\n",
    "outlier_counts = {\n",
    "    \"num_likes\": len(outliers_likes),\n",
    "    \"num_comments\": len(outliers_comments),\n",
    "    \"num_shares\": len(outliers_shares),\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"Outlier Counts:\")\n",
    "for metric, count in outlier_counts.items():\n",
    "    print(f\"{metric}: {count}\")\n",
    "'''print(\"\\nOutliers in num_likes:\\n\", outliers_likes)\n",
    "print(\"\\nOutliers in num_comments:\\n\", outliers_comments)\n",
    "print(\"\\nOutliers in num_shares:\\n\", outliers_shares)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Platform Analysis\n",
    "\n",
    "We will analyze the data with regards to the platforms by calculating the following metrics:\n",
    "\n",
    "01. The number of posts per platform.\n",
    "02. The number of likes per platform.\n",
    "03. The number of comments per platform.\n",
    "04. The number of shares per platform.\n",
    "05. The average number of likes, comments, and shares per post for each platform.\n",
    "06. The total engagement (likes + comments + shares) per platform.\n",
    "07. The average engagement per post for each platform.\n",
    "08. The engagement rate per platform.\n",
    "09. The top 5 posts per platform based on engagement.\n",
    "10. The top 5 posts per platform based on likes.\n",
    "\n",
    "### Platform Segmentation\n",
    "\n",
    "We will segment the platforms by content types: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate platform statistics\n",
    "def calculate_platform_stats(df, output_path=r'C:\\\\Users\\\\EBUKA\\\\Documents\\\\Business Analysis Algorithm\\\\social_data\\\\platform_analyzer.csv'):\n",
    "    \"\"\"\n",
    "    Calculate platform statistics (posts, likes, comments, shares, engagement) and save to CSV.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with social media data.\n",
    "        output_path (str): Path to save the resulting CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with platform statistics, or None if error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Rename columns if needed\n",
    "        df = df.rename(columns={'likes': 'num_likes', 'comments': 'num_comments', 'shares': 'num_shares'})\n",
    "        required_columns = ['platform', 'post_id', 'num_likes', 'num_comments', 'num_shares']\n",
    "        if not all(column in df.columns for column in required_columns):\n",
    "            raise ValueError(\"One or more required columns do not exist in the DataFrame.\")\n",
    "\n",
    "        # Calculate stats\n",
    "        platform_stats = df.groupby('platform').agg(\n",
    "            num_posts=('post_id', 'count'),\n",
    "            num_likes=('num_likes', 'sum'),\n",
    "            num_comments=('num_comments', 'sum'),\n",
    "            num_shares=('num_shares', 'sum')\n",
    "        ).reset_index()\n",
    "        platform_stats['avg_likes'] = (platform_stats['num_likes'] / platform_stats['num_posts']).round(1)\n",
    "        platform_stats['avg_comments'] = (platform_stats['num_comments'] / platform_stats['num_posts']).round(1)\n",
    "        platform_stats['avg_shares'] = (platform_stats['num_shares'] / platform_stats['num_posts']).round(1)\n",
    "        platform_stats['total_engagement'] = platform_stats['num_likes'] + platform_stats['num_comments'] + platform_stats['num_shares']\n",
    "        platform_stats['avg_engagement'] = (platform_stats['total_engagement'] / platform_stats['num_posts']).round(1)\n",
    "\n",
    "        # Save to CSV\n",
    "        platform_stats.to_csv(output_path, index=False)\n",
    "        return platform_stats\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating platform statistics: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "platform_stats = calculate_platform_stats(df)\n",
    "if platform_stats is not None:\n",
    "    display(platform_stats.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'avg_engagement' column is numeric\n",
    "platform_stats['avg_engagement'] = pd.to_numeric(platform_stats['avg_engagement'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'avg_engagement' or 'platform' columns\n",
    "platform_stats = platform_stats.dropna(subset=['avg_engagement', 'platform'])\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Create a bar plot of the average engagement per post per platform\n",
    "sns.barplot(x='platform', y='avg_engagement', data=platform_stats, palette='viridis', ax=ax)\n",
    "\n",
    "# Set the title and labels of the plot\n",
    "ax.set_title('Average Engagement per Post per Platform', fontsize=16)\n",
    "ax.set_xlabel('Platform', fontsize=14)\n",
    "ax.set_ylabel('Average Engagement', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Analysis\n",
    "\n",
    "### Understanding the Problem\n",
    "\n",
    "We will analyze how **social media post engagement** changes over **time** using the date and time columns to find the best posting times and identify trends. We aim to understand how engagement metrics like likes, comments, and shares vary over different time periods. This helps identify when posts get the most interaction, which can guide when to post for maximum impact. With date and time columns, we can analyze daily, weekly, and monthly patterns.\n",
    "\n",
    "### Questions to Explore:\n",
    "\n",
    "1. **Daily Patterns**: What are the peak hours for engagement?\n",
    "2. **Weekly Patterns**: Are there specific days of the week that see higher engagement?\n",
    "3. **Monthly Patterns**: How does engagement vary across different months?\n",
    "4. **Seasonal Trends**: Are there any seasonal trends in engagement? We’ll look at monthly patterns to spot any seasonal highs or lows.\n",
    "5. **Platform-Time Interaction**: How do different platforms perform at different times of the day or week?\n",
    "6. **Posting Time and Engagment Correlation**: Does posting at certain times correlate with higher engagement?\n",
    "\n",
    "### Steps to Perform the Analysis:\n",
    "\n",
    "1. **Exploratory Data Analysis (EDA)**: Visualize engagement metrics over time using line plots, bar plots, and heatmaps.\n",
    "2. **Pattern Identification**: Identify peak times for engagement and trends over different time periods.\n",
    "3. **Comparison Across Platforms**: If data is available for multiple platforms, compare engagement patterns across them.\n",
    "4. **Seasonal Decomposition**: Use time series decomposition to separate the trend, seasonal, and residual components of the data.\n",
    "5. **Hypothesis Testing**: Conduct statistical tests to determine if observed patterns are significant.\n",
    "6. **Reporting**: Summarize findings and create visualizations to communicate the insights effectively.\n",
    "\n",
    "### Relevant Data:\n",
    "\n",
    "1. **Engagement Metrics**: Likes, shares, comments, and views.\n",
    "2. **Posting Timestamps**: The exact time when each post was published.\n",
    "3. **Platform Information**: If data is available for multiple platforms (e.g., Facebook, Instagram, Twitter).\n",
    "\n",
    "\n",
    "### Tools and Techniques:\n",
    "\n",
    "- **Python Libraries**: Pandas, Matplotlib, Seaborn, Statsmodels, and Plotly.\n",
    "- **Time Series Analysis**: ARIMA, SARIMA, and seasonal decomposition.\n",
    "- **Statistical Tests**: T-tests, ANOVA, and Chi-square tests.\n",
    "- **Visualization**: Line plots, bar plots, heatmaps, and box plots.\n",
    "\n",
    "\n",
    "### Steps to Perform the Analysis:\n",
    "\n",
    "1. **Data Combination**: Combine data from different files if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 1. Daily Patterns: What are the peak hours for engagement?'''\n",
    "\n",
    "# Group by time and aggregate engagement metrics\n",
    "peak_hours = df.groupby('time').agg(\n",
    "    num_posts=('post_id', 'count'),\n",
    "    num_likes=('num_likes', 'sum'),\n",
    "    num_comments=('num_comments', 'sum'),\n",
    "    num_shares=('num_shares', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate total engagement and average engagement per post\n",
    "peak_hours['total_engagement'] = peak_hours['num_likes'] + peak_hours['num_comments'] + peak_hours['num_shares']\n",
    "peak_hours['avg_engagement'] = (peak_hours['total_engagement'] / peak_hours['num_posts']).round(1)\n",
    "\n",
    "\n",
    "# Convert the time column to datetime format and extract the hour\n",
    "peak_hours['time'] = pd.to_datetime(peak_hours['time'], format='%I:%M %p').dt.strftime('%H:%M')\n",
    "\n",
    "# Convert the avg_engagement column to numeric format\n",
    "peak_hours['avg_engagement'] = pd.to_numeric(peak_hours['avg_engagement'])\n",
    "\n",
    "# Sort the peak_hours DataFrame by time\n",
    "peak_hours = peak_hours.sort_values('time')\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Plot the average engagement per post by time\n",
    "sns.lineplot(x='time', y='avg_engagement', data=peak_hours, marker='o', color='blue', ax=ax)\n",
    "ax.set_title('Average Engagement per Post by Time')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Engagement')\n",
    "ax.grid(True)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' At what time is there peak engagement for each platform? '''\n",
    "\n",
    "# Group by platform and time, and aggregate engagement metrics\n",
    "platform_peak_hours = df.groupby(['platform', 'time']).agg(\n",
    "    num_posts=('post_id', 'count'),\n",
    "    num_likes=('num_likes', 'sum'),\n",
    "    num_comments=('num_comments', 'sum'),\n",
    "    num_shares=('num_shares', 'sum')\n",
    ").reset_index()\n",
    "# Calculate total engagement and average engagement per post for each platform\n",
    "platform_peak_hours['total_engagement'] = platform_peak_hours['num_likes'] + platform_peak_hours['num_comments'] + platform_peak_hours['num_shares']\n",
    "platform_peak_hours['avg_engagement'] = (platform_peak_hours['total_engagement'] / platform_peak_hours['num_posts']).round(1)\n",
    "# Convert the time column to datetime format and extract the hour for sorting purposes\n",
    "platform_peak_hours['time'] = pd.to_datetime(platform_peak_hours['time'], format='%I:%M %p').dt.strftime('%H:%M')\n",
    "# Convert the avg_engagement column to numeric format\n",
    "platform_peak_hours['avg_engagement'] = pd.to_numeric(platform_peak_hours['avg_engagement'])\n",
    "# Sort the platform_peak_hours DataFrame by platform and time\n",
    "platform_peak_hours = platform_peak_hours.sort_values(['platform', 'time'])\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "# Plot the average engagement per post by time for each platform\n",
    "sns.lineplot(x='time', y='avg_engagement', hue='platform', data=platform_peak_hours, marker='o', ax=ax)\n",
    "ax.set_title('Average Engagement per Post by Time for Each Platform')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Engagement')\n",
    "ax.grid(True)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df.to_csv(r'C:\\\\Users\\\\EBUKA\\\\Documents\\\\Business Analysis Algorithm\\\\social_data\\\\social_media_engagement.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' At what time is there peak and lowest engagement for Facebook? '''\n",
    "\n",
    "# Filter the platform_peak_hours DataFrame for Facebook\n",
    "facebook_peak_hours = platform_peak_hours[platform_peak_hours['platform'] == 'Facebook']\n",
    "\n",
    "# Find the time with the highest and lowest average engagement for Facebook\n",
    "peak_engagement_facebook = facebook_peak_hours.loc[facebook_peak_hours['avg_engagement'].idxmax()]\n",
    "lowest_engagement_facebook = facebook_peak_hours.loc[facebook_peak_hours['avg_engagement'].idxmin()]\n",
    "median_engagement_facebook = facebook_peak_hours['avg_engagement'].median()\n",
    "mean_engagement_facebook = facebook_peak_hours['avg_engagement'].mean().round(1)\n",
    "median_time_facebook = facebook_peak_hours.loc[facebook_peak_hours['avg_engagement'].sub(median_engagement_facebook).abs().idxmin()]['time']\n",
    "dispersion_facebook = facebook_peak_hours['avg_engagement'].std().round(1)\n",
    "\n",
    "# Print the peak and lowest engagement times for Facebook\n",
    "print(\"Peak Engagement Time for Facebook:\")\n",
    "print(peak_engagement_facebook[['time', 'avg_engagement']])\n",
    "print(\"\\nLowest Engagement Time for Facebook:\")\n",
    "print(lowest_engagement_facebook[['time', 'avg_engagement']])\n",
    "\n",
    "# Print the median and mean engagement per post for Facebook\n",
    "print(\"\\nMedian Engagement per Post for Facebook:\", median_engagement_facebook)\n",
    "print(\"Mean Engagement per Post for Facebook:\", mean_engagement_facebook)\n",
    "print(\"Median Time for Facebook:\", median_time_facebook)\n",
    "\n",
    "# Print the dispersion of engagement for Facebook\n",
    "print(\"\\nDispersion of Engagement for Facebook:\", dispersion_facebook)\n",
    "\n",
    "# Determine if the standard deviation is high or low\n",
    "threshold = 0.2  # 20% threshold\n",
    "if dispersion_facebook > threshold * mean_engagement_facebook:\n",
    "    print(\"The standard deviation is high.\")\n",
    "else:\n",
    "    print(\"The standard deviation is low.\")\n",
    "\n",
    "# Sort the facebook_peak_hours DataFrame by time\n",
    "facebook_peak_hours = facebook_peak_hours.sort_values('time')\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Plot the average engagement per post by time for Facebook\n",
    "sns.lineplot(x='time', y='avg_engagement', data=facebook_peak_hours, marker='o', color='blue', ax=ax)\n",
    "ax.set_title('Average Engagement per Post by Time for Facebook')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Engagement')\n",
    "ax.grid(True)\n",
    "\n",
    "# Add a horizontal line for the median engagement per post for Facebook\n",
    "ax.axhline(y=median_engagement_facebook, color='r', linestyle='--', label=f'Median Engagement; {median_engagement_facebook}')\n",
    "\n",
    "# Add a horizontal line for the mean engagement per post for Facebook\n",
    "ax.axhline(y=mean_engagement_facebook, color='g', linestyle='--', label=f'Mean Engagement: {mean_engagement_facebook}')\n",
    "\n",
    "# Add a horizontal line for the threshold\n",
    "ax.axhline(y=mean_engagement_facebook + threshold * mean_engagement_facebook, color='orange', linestyle='--', label=f'Threshold: {threshold * mean_engagement_facebook}')\n",
    "\n",
    "# Add a vertical line for the median time for Facebook\n",
    "ax.axvline(x=median_time_facebook, color='purple', linestyle='--', label=f'Median Time: {median_time_facebook}')\n",
    "\n",
    "# Add a vertical line for the peak engagement time for Facebook\n",
    "ax.axvline(x=peak_engagement_facebook['time'], color='g', linestyle='--', label=f'Peak Engagement Time: {peak_engagement_facebook[\"time\"]}')\n",
    "\n",
    "# Add a vertical line for the lowest engagement time for Facebook\n",
    "ax.axvline(x=lowest_engagement_facebook['time'], color='orange', linestyle='--', label=f'Lowest Engagement Time: {lowest_engagement_facebook[\"time\"]}')\n",
    "\n",
    "# Show dispersion of engagement for Facebook as a shaded area around the median line\n",
    "ax.fill_between(facebook_peak_hours['time'], median_engagement_facebook - dispersion_facebook, median_engagement_facebook + dispersion_facebook, color='r', alpha=0.2, label=f'Dispersion of Engagement: ±{dispersion_facebook}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "facebook_peak_hours.to_csv(r'C:\\\\Users\\\\EBUKA\\\\Documents\\\\Business Analysis Algorithm\\\\social_data\\\\facebook_peak_hours.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''At what time is there peak and lowest engagement for Instagram?'''\n",
    "\n",
    "# Filter the platform_peak_hours DataFrame for Instagram\n",
    "instagram_peak_hours = platform_peak_hours[platform_peak_hours['platform'] == 'Instagram']\n",
    "\n",
    "# Find the time with the highest and lowest average engagement for Instagram\n",
    "peak_engagement_instagram = instagram_peak_hours.loc[instagram_peak_hours['avg_engagement'].idxmax()]\n",
    "lowest_engagement_instagram = instagram_peak_hours.loc[instagram_peak_hours['avg_engagement'].idxmin()]\n",
    "median_engagement_instagram = instagram_peak_hours['avg_engagement'].median()\n",
    "mean_engagement_instagram = instagram_peak_hours['avg_engagement'].mean().round(1)\n",
    "median_time_instagram = instagram_peak_hours.loc[instagram_peak_hours['avg_engagement'].sub(median_engagement_instagram).abs().idxmin()]['time']\n",
    "dispersion_instagram = instagram_peak_hours['avg_engagement'].std().round(1)\n",
    "\n",
    "# Print the peak and lowest engagement times for Instagram\n",
    "print(\"\\nPeak Engagement Time for Instagram:\")\n",
    "print(peak_engagement_instagram[['time', 'avg_engagement']])\n",
    "print(\"\\nLowest Engagement Time for Instagram:\")\n",
    "print(lowest_engagement_instagram[['time', 'avg_engagement']])\n",
    "\n",
    "# Print the median and mean engagement per post for Instagram\n",
    "print(\"\\nMedian Engagement per Post for Instagram:\", median_engagement_instagram)\n",
    "print(\"Mean Engagement per Post for Instagram:\", mean_engagement_instagram)\n",
    "print(\"Median Time for Instagram:\", median_time_instagram)\n",
    "\n",
    "# Print the dispersion of engagement for Instagram\n",
    "print(\"\\nDispersion of Engagement for Instagram:\", dispersion_instagram)\n",
    "\n",
    "# Determine if the standard deviation is high or low\n",
    "threshold = 0.2  # 20% threshold for high dispersion\n",
    "if dispersion_instagram > threshold * mean_engagement_instagram:\n",
    "    print(\"The standard deviation is high.\")\n",
    "else:    \n",
    "    print(\"The standard deviation is low.\")\n",
    "\n",
    "# Sort the instagram_peak_hours DataFrame by time\n",
    "instagram_peak_hours = instagram_peak_hours.sort_values('time')\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Plot the average engagement per post by time for Instagram\n",
    "sns.lineplot(x='time', y='avg_engagement', data=instagram_peak_hours, marker='o', color='blue', ax=ax)\n",
    "ax.set_title('Average Engagement per Post by Time for Instagram')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Engagement')\n",
    "#ax.set_xticks(range(0, 24))  # Set x-ticks to show every hour\n",
    "ax.grid(True)\n",
    "\n",
    "# Add a horizontal line for the median engagement per post for Instagram\n",
    "ax.axhline(y=median_engagement_instagram, color='r', linestyle='--', label=f'Median Engagement: {median_engagement_instagram}')\n",
    "\n",
    "# Add a horizontal line for the mean engagement per post for Instagram\n",
    "ax.axhline(y=mean_engagement_instagram, color='g', linestyle='--', label=f'Mean Engagement: {mean_engagement_instagram}')\n",
    "\n",
    "# Add a horizontal line for the threshold\n",
    "ax.axhline(y=mean_engagement_instagram + threshold * mean_engagement_instagram, color='orange', linestyle='--', label=f'Threshold: {threshold * mean_engagement_instagram}')\n",
    "\n",
    "# Add a vertical line for the median time for Instagram\n",
    "ax.axvline(x=median_time_instagram, color='purple', linestyle='--', label=f'Median Time: {median_time_instagram}')\n",
    "\n",
    "# Add a vertical line for the peak engagement time for Instagram\n",
    "ax.axvline(x=peak_engagement_instagram['time'], color='g', linestyle='--', label=f'Peak Engagement Time: {peak_engagement_instagram[\"time\"]}')\n",
    "\n",
    "# Add a vertical line for the lowest engagement time for Instagram\n",
    "ax.axvline(x=lowest_engagement_instagram['time'], color='orange', linestyle='--', label=f'Lowest Engagement Time: {lowest_engagement_instagram[\"time\"]}')\n",
    "\n",
    "# Show dispersion of engagement for Instagram as a shaded area around the median line\n",
    "ax.fill_between(instagram_peak_hours['time'], median_engagement_instagram - dispersion_instagram, median_engagement_instagram + dispersion_instagram, color='r', alpha=0.2, label=f'Dispersion of Engagement: ±{dispersion_instagram}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "instagram_peak_hours.to_csv(r'C:\\\\Users\\\\EBUKA\\\\Documents\\\\Business Analysis Algorithm\\\\social_data\\\\instagram_peak_hours.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' At what time is there peak and lowest engagement for Twitter? '''\n",
    "\n",
    "# Filter the platform_peak_hours DataFrame for Twitter\n",
    "twitter_peak_hours = platform_peak_hours[platform_peak_hours['platform'] == 'Twitter']\n",
    "\n",
    "# Find the time with the highest and lowest average engagement for Twitter\n",
    "peak_engagement_twitter = twitter_peak_hours.loc[twitter_peak_hours['avg_engagement'].idxmax()]\n",
    "lowest_engagement_twitter = twitter_peak_hours.loc[twitter_peak_hours['avg_engagement'].idxmin()]\n",
    "median_engagement_twitter = twitter_peak_hours['avg_engagement'].median()\n",
    "mean_engagement_twitter = twitter_peak_hours['avg_engagement'].mean().round(1)\n",
    "median_time_twitter = twitter_peak_hours.loc[twitter_peak_hours['avg_engagement'].sub(median_engagement_twitter).abs().idxmin()]['time']\n",
    "dispersion_twitter = twitter_peak_hours['avg_engagement'].std().round(1)\n",
    "\n",
    "# Print the peak and lowest engagement times for Twitter\n",
    "print(\"Peak Engagement Time for Twitter:\")\n",
    "print(peak_engagement_twitter[['time', 'avg_engagement']])\n",
    "print(\"\\nLowest Engagement Time for Twitter:\")\n",
    "print(lowest_engagement_twitter[['time', 'avg_engagement']])\n",
    "\n",
    "# Print the median and mean engagement per post for Twitter\n",
    "print(\"\\nMedian Engagement per Post for Twitter:\", median_engagement_twitter)\n",
    "print(\"Mean Engagement per Post for Twitter:\", mean_engagement_twitter)\n",
    "print(\"Median Time for Twitter:\", median_time_twitter)\n",
    "\n",
    "# Print the dispersion of engagement for Twitter\n",
    "print(\"\\nDispersion of Engagement for Twitter:\", dispersion_twitter)\n",
    "\n",
    "# Determine if the standard deviation is high or low\n",
    "threshold = 0.2  # 20% threshold\n",
    "if dispersion_twitter > threshold * mean_engagement_twitter:\n",
    "    print(\"The standard deviation is high.\")\n",
    "else:\n",
    "    print(\"The standard deviation is low.\")\n",
    "\n",
    "# Sort the twitter_peak_hours DataFrame by time\n",
    "twitter_peak_hours = twitter_peak_hours.sort_values('time')\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Plot the average engagement per post by time for Twitter\n",
    "sns.lineplot(x='time', y='avg_engagement', data=twitter_peak_hours, marker='o', color='blue', ax=ax)\n",
    "ax.set_title('Average Engagement per Post by Time for Twitter')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Engagement')\n",
    "ax.grid(True)\n",
    "\n",
    "# Add a horizontal line for the median engagement per post for Twitter\n",
    "ax.axhline(y=median_engagement_twitter, color='r', linestyle='--', label=f'Median Engagement: {median_engagement_twitter}')\n",
    "\n",
    "# Add a horizontal line for the mean engagement per post for Twitter\n",
    "ax.axhline(y=mean_engagement_twitter, color='g', linestyle='--', label=f'Mean Engagement: {mean_engagement_twitter}')\n",
    "\n",
    "# Add a horizontal line for the threshold\n",
    "ax.axhline(y=mean_engagement_twitter + threshold * mean_engagement_twitter, color='orange', linestyle='--', label=f'Threshold: {threshold * mean_engagement_twitter}')\n",
    "\n",
    "# Add a vertical line for the median time for Twitter\n",
    "ax.axvline(x=median_time_twitter, color='purple', linestyle='--', label=f'Median Time: {median_time_twitter}')\n",
    "\n",
    "# Add a vertical line for the peak engagement time for Twitter\n",
    "ax.axvline(x=peak_engagement_twitter['time'], color='g', linestyle='--', label=f'Peak Engagement Time: {peak_engagement_twitter[\"time\"]}')\n",
    "\n",
    "# Add a vertical line for the lowest engagement time for Twitter\n",
    "ax.axvline(x=lowest_engagement_twitter['time'], color='orange', linestyle='--', label=f'Lowest Engagement Time: {lowest_engagement_twitter[\"time\"]}')\n",
    "\n",
    "# Show dispersion of engagement for Twitter as a shaded area around the median line\n",
    "ax.fill_between(twitter_peak_hours['time'], median_engagement_twitter - dispersion_twitter, median_engagement_twitter + dispersion_twitter, color='r', alpha=0.2, label=f'Dispersion of Engagement: ±{dispersion_twitter}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "twitter_peak_hours.to_csv(r'C:\\\\Users\\\\EBUKA\\\\Documents\\\\Business Analysis Algorithm\\\\social_data\\\\twitter_peak_hours.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Are there specific days of the week that see higher engagement?\n",
    "List variables to be used for this analysis:\n",
    "- post_day\n",
    "- num_likes, num_comments, num_shares,num_posts\n",
    "- total_engagement\n",
    "- avg_engagement\n",
    "''' \n",
    "\n",
    "# Group by post_day and aggregate engagement metrics\n",
    "daily_engagement = df.groupby('post_day').agg(\n",
    "    num_posts=('post_id', 'count'),\n",
    "    num_likes=('num_likes', 'sum'),\n",
    "    num_comments=('num_comments', 'sum'),\n",
    "    num_shares=('num_shares', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate total engagement and average engagement per post\n",
    "daily_engagement['total_engagement'] = daily_engagement['num_likes'] + daily_engagement['num_comments'] + daily_engagement['num_shares']\n",
    "daily_engagement['avg_engagement'] = (daily_engagement['total_engagement'] / daily_engagement['num_posts']).round(1)\n",
    "\n",
    "# Sort the daily_engagement DataFrame by post_day (Sunday to Saturday)\n",
    "daily_engagement = daily_engagement.sort_values('post_day', key=lambda x: pd.Categorical(x, categories=['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], ordered=True))\n",
    "\n",
    "\n",
    "# Display the daily_engagement DataFrame\n",
    "daily_engagement.head(7)\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# Plot the total engagement per day of the week\n",
    "sns.barplot(x='post_day', y='total_engagement', data=daily_engagement, palette='viridis', ax=ax)\n",
    "# Set plot title and labels\n",
    "ax.set_title('Total Engagement per Day of the Week')\n",
    "ax.set_xlabel('Day of the Week')\n",
    "ax.set_ylabel('Total Engagement')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "daily_engagement.to_csv(r'C:\\\\Users\\\\EBUKA\\\\Documents\\\\Business Analysis Algorithm\\\\social_data\\\\daily_engagement.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''How does engagement vary across different months?'''\n",
    "\n",
    "# Extract the month from the date column\n",
    "df['post_month'] = pd.to_datetime(df['date'], format='%d-%m-%Y').dt.strftime('%B')\n",
    "\n",
    "# Group by month and calculate total engagement and average engagement per post\n",
    "monthly_engagement = df.groupby('post_month').agg(\n",
    "    num_posts=('post_id', 'count'),\n",
    "    num_likes=('num_likes', 'sum'),\n",
    "    num_comments=('num_comments', 'sum'),\n",
    "    num_shares=('num_shares', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate total engagement and average engagement per post for each month\n",
    "monthly_engagement['total_engagement'] = monthly_engagement['num_likes'] + monthly_engagement['num_comments'] + monthly_engagement['num_shares']\n",
    "monthly_engagement['avg_engagement'] = (monthly_engagement['total_engagement'] / monthly_engagement['num_posts']).round(1)\n",
    "\n",
    "# Sort the monthly_engagement DataFrame by month\n",
    "monthly_engagement = monthly_engagement.sort_values('post_month', key=lambda x: pd.Categorical(x, categories=['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'], ordered=True))\n",
    "\n",
    "# Display the monthly_engagement DataFrame\n",
    "monthly_engagement.head(12)\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the total engagement per month\n",
    "sns.barplot(x='post_month', y='total_engagement', data=monthly_engagement, palette='viridis', ax=ax)\n",
    "\n",
    "# Add labels and title to the plot\n",
    "ax.set_title('Total Engagement per Month')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Total Engagement')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "monthly_engagement.to_csv(r'C:\\\\Users\\\\EBUKA\\\\Documents\\\\Business Analysis Algorithm\\\\social_data\\\\monthly_engagement.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''What percentage of our total engagement occurs during each hour of the day?'''\n",
    "\n",
    "# Group by time and calculate total engagement\n",
    "hourly_engagement = df.groupby('time').agg(\n",
    "    num_posts=('post_id', 'count'),\n",
    "    num_likes=('num_likes', 'sum'),\n",
    "    num_comments=('num_comments', 'sum'),\n",
    "    num_shares=('num_shares', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate total engagement and percentage of total engagement per hour\n",
    "hourly_engagement['total_engagement'] = hourly_engagement['num_likes'] + hourly_engagement['num_comments'] + hourly_engagement['num_shares']\n",
    "hourly_engagement['percentage_engagement'] = (hourly_engagement['total_engagement'] / hourly_engagement['total_engagement'].sum()) * 100\n",
    "\n",
    "# Convert the 'time' column to datetime format\n",
    "hourly_engagement['time'] = pd.to_datetime(hourly_engagement['time'], format='%I:%M %p').dt.time\n",
    "\n",
    "# Sort by time to maintain chronological order\n",
    "hourly_engagement = hourly_engagement.sort_values('time')\n",
    "\n",
    "# Group time into morning, afternoon, evening, and night categories\n",
    "hourly_engagement['time_of_day'] = pd.cut(hourly_engagement['time'].apply(lambda x: x.hour), bins=[0, 12, 17, 21, 24], labels=['Morning', 'Afternoon', 'Evening', 'Night'], right=False)\n",
    "\n",
    "# Group by time_of_day\n",
    "hourly_engagement = hourly_engagement.groupby('time_of_day').agg(\n",
    "    num_posts=('num_posts', 'sum'),\n",
    "    num_likes=('num_likes', 'sum'),\n",
    "    num_comments=('num_comments', 'sum'),\n",
    "    num_shares=('num_shares', 'sum'),\n",
    "    total_engagement=('total_engagement', 'sum'),\n",
    "    percentage_engagement=('percentage_engagement', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Plot a pie chart of the percentage of total engagement per time of day\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Create a 3d pie chart\n",
    "ax.pie(hourly_engagement['percentage_engagement'], labels=hourly_engagement['time_of_day'], autopct='%1.1f%%', startangle=140, explode=(0.1, 0, 0, 0), shadow=False) \n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax.axis('equal')\n",
    "\n",
    "# Set title and show plot\n",
    "ax.set_title('Percentage of Total Engagement per Time of Day')\n",
    "ax.legend(title='Time of Day', loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Is there a noticeable difference between weekday and weekend engagement?'''\n",
    "\n",
    "# Group by day of the week and calculate total engagement\n",
    "daily_engagement = df.groupby('post_day').agg(\n",
    "    num_posts=('post_id', 'count'),\n",
    "    num_likes=('num_likes', 'sum'),\n",
    "    num_comments=('num_comments', 'sum'),\n",
    "    num_shares=('num_shares', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Sort the daily_engagement DataFrame by post_day (Sunday to Saturday)\n",
    "daily_engagement = daily_engagement.sort_values('post_day', key=lambda x: pd.Categorical(x, categories=['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], ordered=True))\n",
    "\n",
    "# Calculate total engagement and average engagement per post for each day of the week\n",
    "daily_engagement['total_engagement'] = daily_engagement['num_likes'] + daily_engagement['num_comments'] + daily_engagement['num_shares']\n",
    "daily_engagement['avg_engagement'] = (daily_engagement['total_engagement'] / daily_engagement['num_posts']).round(1)\n",
    "\n",
    "# Group days into weekday and weekend categories\n",
    "daily_engagement['day_category'] = daily_engagement['post_day'].apply(lambda x: 'Weekend' if x in ['Saturday', 'Sunday'] else 'Weekday')\n",
    "\n",
    "# Group by day_category and calculate total engagement and average engagement per post for each category\n",
    "category_engagement = daily_engagement.groupby('day_category').agg(\n",
    "    total_engagement=('total_engagement', 'sum'),\n",
    "    avg_engagement=('avg_engagement', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Display the category_engagement DataFrame\n",
    "category_engagement.head(2)\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the total engagement for each category as a bar plot\n",
    "ax.bar(category_engagement['day_category'], category_engagement['total_engagement'], color=['blue', 'red'])\n",
    "\n",
    "# Set title and labels\n",
    "ax.set_title('Total Engagement by Day Category')\n",
    "ax.set_xlabel('Day Category')\n",
    "ax.set_ylabel('Total Engagement')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''What is the average engagement rate for content posted between 7-9am versus 7-9pm?'''\n",
    "\n",
    "# Group by post_hour and calculate total engagement\n",
    "hourly_engagement = df.groupby('post_hour').agg(\n",
    "    num_posts=('post_id', 'count'),\n",
    "    num_likes=('num_likes', 'sum'),\n",
    "    num_comments=('num_comments', 'sum'),\n",
    "    num_shares=('num_shares', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate total engagement\n",
    "hourly_engagement['total_engagement'] = hourly_engagement['num_likes'] + hourly_engagement['num_comments'] + hourly_engagement['num_shares']\n",
    "\n",
    "# Filter the DataFrame for posts between 7-9am and 7-9pm\n",
    "morning_posts = hourly_engagement[(hourly_engagement['post_hour'] >= 7) & (hourly_engagement['post_hour'] < 9)]\n",
    "evening_posts = hourly_engagement[(hourly_engagement['post_hour'] >= 19) & (hourly_engagement['post_hour'] < 21)]\n",
    "\n",
    "# Calculate the average engagement rate for morning and evening posts\n",
    "morning_avg_engagement = (morning_posts['total_engagement'].sum() / morning_posts['num_posts'].sum()).round(1)\n",
    "evening_avg_engagement = (evening_posts['total_engagement'].sum() / evening_posts['num_posts'].sum()).round(1)\n",
    "\n",
    "# Print the average engagement rate for morning and evening posts\n",
    "print(\"Average Engagement Rate for Morning Posts (7-9am):\", morning_avg_engagement)\n",
    "print(\"Average Engagement Rate for Evening Posts (7-9pm):\", evening_avg_engagement)\n",
    "\n",
    "# Create a bar plot to compare the average engagement rates\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(['Morning (7-9am)', 'Evening (7-9pm)'], [morning_avg_engagement, evening_avg_engagement], color=['blue', 'green'])\n",
    "\n",
    "# Set title and labels\n",
    "ax.set_title('Average Engagement Rate for Morning vs. Evening Posts')\n",
    "ax.set_xlabel('Time of Day')\n",
    "ax.set_ylabel('Average Engagement Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Content Type Analysis'''\n",
    "\n",
    "# Group by post_type and calculate total engagement\n",
    "content_type_engagement = df.groupby('post_type').agg(\n",
    "    num_posts=('post_id', 'count'),\n",
    "    num_likes=('num_likes', 'sum'),\n",
    "    num_comments=('num_comments', 'sum'),\n",
    "    num_shares=('num_shares', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate total engagement and average engagement per post for each content type\n",
    "content_type_engagement['total_engagement'] = content_type_engagement['num_likes'] + content_type_engagement['num_comments'] + content_type_engagement['num_shares']\n",
    "content_type_engagement['avg_engagement_per_post'] = content_type_engagement['total_engagement'] / content_type_engagement['num_posts']\n",
    "\n",
    "content_type_engagement['day_of_week'] = pd.to_datetime(df['date'], format='%d-%m-%Y').dt.day_name()\n",
    "\n",
    "# Print the content type engagement data\n",
    "print('Content Type Engagement:', '\\n')\n",
    "print(content_type_engagement.head(8))\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the average engagement per post by content type\n",
    "sns.barplot(x='post_type', y='avg_engagement_per_post', data=content_type_engagement, palette='viridis', ax=ax)\n",
    "\n",
    "# Set title and labels\n",
    "ax.set_title('Average Engagement per Post by Content Type')\n",
    "ax.set_xlabel('Content Type')\n",
    "ax.set_ylabel('Average Engagement per Post')\n",
    "\n",
    "# Annotate the bars with the average engagement values\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.1f}\", (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a table that counts the number of post types across each day of week\n",
    "day_of_week_post_type = df.groupby(['day_of_week', 'post_type']).size().unstack().fillna(0)\n",
    "\n",
    "# Calculate engagement metrics for each post type\n",
    "day_of_week_post_type['total_posts'] = day_of_week_post_type.sum(axis=1)\n",
    "day_of_week_post_type['total_likes'] = df.groupby('day_of_week')['num_likes'].sum()\n",
    "day_of_week_post_type['total_comments'] = df.groupby('day_of_week')['num_comments'].sum()\n",
    "day_of_week_post_type['total_shares'] = df.groupby('day_of_week')['num_shares'].sum()\n",
    "day_of_week_post_type['total_engagement'] = day_of_week_post_type['total_likes'] + day_of_week_post_type['total_comments'] + day_of_week_post_type['total_shares']\n",
    "day_of_week_post_type['avg_engagement_per_post'] = day_of_week_post_type['total_engagement'] / day_of_week_post_type['total_posts']\n",
    "\n",
    "# Sort from Sunday to Saturday\n",
    "day_of_week_post_type = day_of_week_post_type.reindex(['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])\n",
    "\n",
    "# Plot the total posts by day of week and post type\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars = day_of_week_post_type['total_posts'].plot(kind='bar', stacked=True, ax=ax)\n",
    "\n",
    "# Add text annotations to each bar\n",
    "for bar in bars.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.0f}', ha='center', va='bottom')\n",
    "\n",
    "ax.set_title('Total Posts by Day of Week and Post Type')\n",
    "ax.set_xlabel('Day of Week')\n",
    "ax.set_ylabel('Total Posts')\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation = 0)\n",
    "plt.show()\n",
    "\n",
    "# Print the table of post types by day of week\n",
    "day_of_week_post_type.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Find out distribution of carousel across each day of the week'''\n",
    "\n",
    "# Filter the DataFrame for carousel posts\n",
    "carousel_posts = df[df['post_type'] == 'carousel']\n",
    "\n",
    "# Extract the day of the week from the date column\n",
    "carousel_posts['day_of_week'] = pd.to_datetime(carousel_posts['date']).dt.day_name()\n",
    "\n",
    "# Group by day of the week and count the number of carousel posts\n",
    "carousel_count_by_day = carousel_posts['day_of_week'].value_counts().reindex(['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])\n",
    "\n",
    "# Plot carousel count vs day of week\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars = carousel_count_by_day.plot(kind='bar', ax=ax)\n",
    "\n",
    "# Add text annotations to each bar\n",
    "for bar in bars.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.0f}', ha='center', va='bottom')\n",
    "\n",
    "ax.set_title('Carousel Posts by Day of Week')\n",
    "ax.set_xlabel('Day of Week')\n",
    "ax.set_ylabel('Number of Carousel Posts')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculate engagement metrics for carousel posts for each day of the week'''\n",
    "\n",
    "# Filter the DataFrame for carousel posts\n",
    "carousel_posts = df[df['post_type'] == 'carousel'].copy()\n",
    "\n",
    "# Extract the day of the week from the date column\n",
    "carousel_posts.loc[:, 'day_of_week'] = pd.to_datetime(carousel_posts['date'], dayfirst=True).dt.day_name()\n",
    "\n",
    "# Calculate total engagement\n",
    "carousel_posts.loc[:, 'total_engagement'] = carousel_posts['num_likes'] + carousel_posts['num_comments'] + carousel_posts['num_shares']\n",
    "\n",
    "# Group by day of the week and calculate engagement metrics\n",
    "engagement_metrics_by_day = carousel_posts.groupby('day_of_week').agg(\n",
    "    total_likes=('num_likes', 'sum'),\n",
    "    total_comments=('num_comments', 'sum'),\n",
    "    total_shares=('num_shares', 'sum'),     \n",
    "    total_engagement=('total_engagement', 'sum'),   \n",
    "    avg_engagement_per_post=('total_engagement', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Sort the days of the week in the correct order\n",
    "days_order = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "engagement_metrics_by_day['day_of_week'] = pd.Categorical(engagement_metrics_by_day['day_of_week'], categories=days_order, ordered=True)\n",
    "engagement_metrics_by_day = engagement_metrics_by_day.sort_values('day_of_week')\n",
    "\n",
    "# Display the result\n",
    "print('Engagement metrics for carousel post for each day of the week', '\\n')\n",
    "print(engagement_metrics_by_day.head(7))\n",
    "\n",
    "# Plot carousel count vs day of week\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars = ax.bar(engagement_metrics_by_day['day_of_week'], engagement_metrics_by_day['avg_engagement_per_post'])\n",
    "\n",
    "# Add text annotations to each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "ax.set_title('Average Engagement per Carousel Post by Day of Week')\n",
    "ax.set_xlabel('Day of Week')\n",
    "ax.set_ylabel('Average Engagement')\n",
    "plt.graph()\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Interaction between carousel post per week andn average engagement per post'''\n",
    "\n",
    "# Extract the day of the week from the date column\n",
    "carousel_posts.loc[:, 'day_of_week'] = pd.to_datetime(carousel_posts['date'], dayfirst=True).dt.day_name()\n",
    "\n",
    "# Calculate total engagement\n",
    "carousel_posts.loc[:, 'total_engagement'] = carousel_posts['num_likes'] + carousel_posts['num_comments'] + carousel_posts['num_shares']\n",
    "# Gropup by week and calculate the number of carousel posts and average engagement per post\n",
    "carousel_weekly = carousel_posts.groupby('day_of_week').agg(\n",
    "    num_carousel_posts=('post_type', 'count'),\n",
    "    avg_engagement_per_post=('total_engagement', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Sort the days of the week in the correct order\n",
    "days_order = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "carousel_weekly['day_of_week'] = pd.Categorical(carousel_weekly['day_of_week'], categories=days_order, ordered=True)\n",
    "carousel_weekly = carousel_weekly.sort_values('day_of_week')\n",
    "\n",
    "# Display the result\n",
    "print('Interaction between carousel post per week and average engagement per post', '\\n')\n",
    "print(carousel_weekly.head(7))\n",
    "\n",
    "# Plot the number of carousel posts and average engagement per post by day of week\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# Plot the number of carousel posts\n",
    "ax.bar(carousel_weekly['day_of_week'], carousel_weekly['num_carousel_posts'], label='Number of Carousel Posts')\n",
    "# Plot the average engagement per post\n",
    "ax.plot(carousel_weekly['day_of_week'], carousel_weekly['avg_engagement_per_post'], color='red', marker='o', label='Average Engagement per Post')\n",
    "\n",
    "# Add text annotations to each bar for number of carousel posts\n",
    "for bar in ax.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.0f}', ha='center', va='bottom')\n",
    "\n",
    "# Add text annotations to the line plot for average engagement per post\n",
    "for i, txt in enumerate(carousel_weekly['avg_engagement_per_post']):\n",
    "    ax.annotate(f'{txt:.2f}', (carousel_weekly['day_of_week'].iloc[i], carousel_weekly['avg_engagement_per_post'].iloc[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "ax.set_title('Interaction between Carousel Posts per Week and Average Engagement per Post')\n",
    "ax.set_xlabel('Day of Week')\n",
    "ax.set_ylabel('Number of Carousel Posts')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Find out distribution of image posts across each day of the week'''\n",
    "\n",
    "# Filter the DataFrame for image posts\n",
    "image_posts = df[df['post_type'] == 'image'].copy()\n",
    "\n",
    "# Extract the day of the week from the date column for image posts\n",
    "image_posts['day_of_week'] = pd.to_datetime(image_posts['date']).dt.day_name()\n",
    "\n",
    "# Group by day of the week and count the number of image posts\n",
    "image_count_by_day = image_posts['day_of_week'].value_counts().reindex(['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])\n",
    "\n",
    "# Plot image count vs day of week\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars = ax.bar(image_count_by_day.index, image_count_by_day.values)\n",
    "\n",
    "# Add text annotations to each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.0f}', ha='center', va='bottom')\n",
    "\n",
    "ax.set_title('Image Posts by Day of Week')\n",
    "ax.set_xlabel('Day of Week')\n",
    "ax.set_ylabel('Number of Image Posts')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further analysis for Facebook\n",
    "\n",
    "### Missed Question: Are there patterns in content type, posting frequency, or external factors (e.g., weekdays vs. weekends) that explain peak/lowest engagement?\n",
    "\n",
    "**Why It Matters**: Knowing why certain times perform better could inform strategy (e.g., posting during peak user activity or targeting specific audiences).\n",
    "**How to Analyze**: If your platform_peak_hours or larger dataset includes columns like content_type, day_of_week, or post_count, you could:\n",
    "\n",
    "## DECODE Framework\n",
    "\n",
    "### Decompose\n",
    "**Define and Decompose**\n",
    "\n",
    "Main task crux of this task is to find patterns that explain peak/lowest engagement.\n",
    "\n",
    "Variables needed as represented in data set:\n",
    "\n",
    "1. **time**: The time of the post. This is the main variable we are interested in. It will help us identify peak and lowest engagement times.\n",
    "2. **num_likes**: The number of likes on the post. This is the engagement metric we are interested in. It will help us identify peak and lowest engagement times.\n",
    "3. **num_shares**: The number of shares on the post. This is another engagement metric we are interested in. It will help us identify peak and lowest engagement times.\n",
    "4. **num_comments**: The number of comments on the post. This is another engagement metric we are interested in. It will help us identify peak and lowest engagement times.\n",
    "5. **post_day**: The day of the week the post was made. This will help us identify if there are any patterns in engagement based on the day of the week.\n",
    "6. **post_type**: The type of post (e.g., image, video, link). This will help us identify if there are any patterns in engagement based on the type of post.\n",
    "7. **avg_engagement**: The average engagement (likes, shares, comments) per post. This will help us identify peak and lowest engagement times.\n",
    "\n",
    "\n",
    "### Explore and Extract\n",
    "Pattern Recognition and Knowledge Connection\n",
    "\n",
    "We need to explore the data to find patterns that explain peak/lowest engagement. We can do this by:\n",
    "1. Grouping the data by time and calculating the average engagement for each time.\n",
    "2. Grouping the data by post_day and calculating the average engagement for each day.\n",
    "3. Grouping the data by post_type and calculating the average engagement for each type.\n",
    "4. Grouping the data by time and post_day and calculating the average engagement for each combination.\n",
    "\n",
    "Do this by using pandas groupby function and then plot the results using matplotlib.\n",
    "\n",
    "\n",
    "### Construct and Calculate\n",
    "Solution Stategy and Implementation\n",
    "\n",
    "### Observe and Optimize\n",
    "Result Analysis and Solution Refinement\n",
    "\n",
    "### Derive and Document\n",
    "Knowledge Extraction and Meta-Analysis\n",
    "\n",
    "### Extend and Evolve\n",
    "Generalization and Understanding Deepening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query and Python code to create a MySQL database using SQLAlchemy and environment variables\n",
    "import os\n",
    "import urllib.parse\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get database credentials from environment variables\n",
    "mysql_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "\n",
    "# Validate that password exists\n",
    "if not db_password:\n",
    "    raise ValueError(\"Database password not found in environment variables. Please set DB_PASSWORD in your .env file.\")\n",
    "\n",
    "# URL-encode the password to handle special characters\n",
    "db_password_encoded = urllib.parse.quote_plus(db_password)\n",
    "\n",
    "# Create engine for MySQL server (no database specified)\n",
    "engine = create_engine(f\"mysql+pymysql://{mysql_user}:{db_password_encoded}@{host}/\")\n",
    "\n",
    "# SQL query to create the database if it doesn't exist\n",
    "create_db_query = f\"CREATE DATABASE IF NOT EXISTS {db_name};\"\n",
    "\n",
    "# Execute the query with error handling\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(create_db_query))\n",
    "        print(f\"Database '{db_name}' created or already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating database: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    # Close the engine connection\n",
    "    engine.dispose()\n",
    "\n",
    "print(f\"Database setup complete. You can now connect using:\")\n",
    "print(f\"engine = create_engine('mysql+pymysql://{mysql_user}:{db_password_encoded}@{host}/{db_name}')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
